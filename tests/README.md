# DualMind Test Suite

Comprehensive test suite for DualMind AI Chatbot covering unit tests, integration tests, and UI tests.

## ğŸ“ Test Structure

```
tests/
â”œâ”€â”€ __init__.py              # Test package initialization
â”œâ”€â”€ conftest.py              # Pytest configuration and fixtures
â”œâ”€â”€ requirements-test.txt    # Test dependencies
â”œâ”€â”€ unit/                    # Unit tests
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ test_server.py       # Server endpoint tests
â”œâ”€â”€ integration/             # Integration tests
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ test_rag.py          # RAG functionality tests
â””â”€â”€ ui/                      # UI tests
    â”œâ”€â”€ __init__.py
    â””â”€â”€ test_ui.py           # UI component tests
```

## ğŸš€ Quick Start

### 1. Install Test Dependencies

```bash
pip install -r tests/requirements-test.txt
```

Or install with main dependencies:

```bash
pip install -r requirements.txt
pip install pytest pytest-cov pytest-asyncio
```

### 2. Run All Tests

```bash
# From project root
pytest

# With coverage report
pytest --cov=. --cov-report=html

# Verbose output
pytest -v
```

### 3. Run Specific Test Categories

```bash
# Unit tests only
pytest tests/unit/

# Integration tests only
pytest tests/integration/

# UI tests only
pytest tests/ui/

# Run specific test file
pytest tests/unit/test_server.py

# Run specific test class
pytest tests/unit/test_server.py::TestHealthEndpoint

# Run specific test method
pytest tests/unit/test_server.py::TestHealthEndpoint::test_health_check_status
```

## ğŸ“Š Test Coverage

### Unit Tests (`tests/unit/`)

Tests individual components and functions in isolation.

**Coverage:**
- âœ… Health check endpoint
- âœ… Cloud provider endpoints (Google, OpenAI, Anthropic, NVIDIA, Azure)
- âœ… Provider model listing
- âœ… Embedding provider endpoints
- âœ… Embedding model listing (Cloud & Local)
- âœ… RAG document management (upload, list, delete)
- âœ… UI serving endpoints
- âœ… Static file serving
- âœ… Chat endpoint structure

**Example:**
```bash
pytest tests/unit/test_server.py -v
```

### Integration Tests (`tests/integration/`)

Tests interactions between multiple components.

**Coverage:**
- âœ… Document processing (TXT, MD, PDF, DOCX)
- âœ… Document chunking with overlap
- âœ… Document storage and retrieval
- âœ… Semantic search functionality
- âœ… Embedding service integration
- âœ… Multi-session handling
- âœ… End-to-end RAG workflow

**Example:**
```bash
pytest tests/integration/test_rag.py -v
```

### UI Tests (`tests/ui/`)

Tests user interface components and interactions.

**Coverage:**
- âœ… Landing page rendering
- âœ… Local mode UI loading
- âœ… Cloud mode UI loading
- âœ… Enhanced UI with modern design
- âœ… Sidebar and chat history
- âœ… Model selector functionality
- âœ… Markdown and code highlighting
- âœ… Responsive design
- âœ… Accessibility features
- âœ… Dark mode styling
- âœ… Static asset serving

**Example:**
```bash
pytest tests/ui/test_ui.py -v
```

## ğŸ“ Writing New Tests

### Test File Naming

- Unit tests: `test_<module_name>.py`
- Integration tests: `test_<feature_name>.py`
- UI tests: `test_<component_name>.py`

### Test Class Naming

```python
class TestFeatureName:
    """Test feature description"""
    
    def setup_method(self):
        """Setup before each test"""
        pass
    
    def test_specific_behavior(self):
        """Test specific behavior"""
        assert True
```

### Using Fixtures

```python
def test_with_fixture(test_session_id, sample_document):
    """Test using fixtures from conftest.py"""
    assert test_session_id is not None
    assert sample_document["filename"] == "test_document.txt"
```

### Test Markers

```python
import pytest

@pytest.mark.unit
def test_unit_functionality():
    """Mark as unit test"""
    pass

@pytest.mark.integration
def test_integration_functionality():
    """Mark as integration test"""
    pass

@pytest.mark.slow
def test_slow_operation():
    """Mark as slow test"""
    pass

@pytest.mark.requires_api_key
def test_with_api_key():
    """Mark as requiring API key"""
    pass
```

Run specific markers:
```bash
pytest -m unit        # Run only unit tests
pytest -m integration # Run only integration tests
pytest -m "not slow"  # Skip slow tests
```

## ğŸ” Test Examples

### Testing API Endpoints

```python
from fastapi.testclient import TestClient
from server import app

def test_health_endpoint():
    client = TestClient(app)
    response = client.get("/health")
    assert response.status_code == 200
    assert response.json()["status"] == "healthy"
```

### Testing Document Processing

```python
from document_processor import DocumentProcessor

def test_process_document():
    processor = DocumentProcessor()
    result = processor.process("Test content", "test.txt")
    assert result is not None
    assert "test" in result.lower()
```

### Testing RAG Workflow

```python
def test_rag_workflow(test_session_id):
    from document_processor import DocumentProcessor, DocumentChunker, DocumentStore
    
    processor = DocumentProcessor()
    chunker = DocumentChunker()
    store = DocumentStore()
    
    # Process
    content = processor.process("Test document", "test.txt")
    
    # Chunk
    chunks = chunker.chunk(content)
    
    # Store
    doc_id = store.add_document(test_session_id, "test.txt", content)
    
    assert doc_id is not None
    assert len(chunks) > 0
```

## ğŸ“ˆ Coverage Reports

### Generate HTML Coverage Report

```bash
pytest --cov=. --cov-report=html
```

View report:
```bash
open htmlcov/index.html  # macOS
xdg-open htmlcov/index.html  # Linux
```

### Coverage Summary

```bash
pytest --cov=. --cov-report=term-missing
```

## ğŸ› Debugging Tests

### Run with Print Statements

```bash
pytest -s tests/unit/test_server.py
```

### Run with PDB Debugger

```python
def test_with_debugger():
    import pdb; pdb.set_trace()
    assert True
```

### Show Local Variables on Failure

```bash
pytest -l tests/unit/test_server.py
```

### Stop on First Failure

```bash
pytest -x
```

### Run Last Failed Tests

```bash
pytest --lf
```

## ğŸ¯ Best Practices

1. **Write descriptive test names**
   - âœ… `test_health_endpoint_returns_200`
   - âŒ `test_health`

2. **One assertion concept per test**
   - Test one thing at a time
   - Makes debugging easier

3. **Use fixtures for common setup**
   - Defined in `conftest.py`
   - Reusable across tests

4. **Mock external dependencies**
   - Don't make real API calls in tests
   - Use `pytest-mock` or `unittest.mock`

5. **Test edge cases**
   - Empty inputs
   - Invalid data
   - Boundary conditions

6. **Keep tests fast**
   - Unit tests should run in milliseconds
   - Mark slow tests with `@pytest.mark.slow`

7. **Test both success and failure cases**
   - Happy path
   - Error conditions

## ğŸ”§ Continuous Integration

### GitHub Actions Example

```yaml
name: Tests

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v2
    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.9'
    
    - name: Install dependencies
      run: |
        pip install -r requirements.txt
        pip install -r tests/requirements-test.txt
    
    - name: Run tests
      run: pytest --cov=. --cov-report=xml
    
    - name: Upload coverage
      uses: codecov/codecov-action@v2
```

## ğŸ“š Additional Resources

- [Pytest Documentation](https://docs.pytest.org/)
- [FastAPI Testing](https://fastapi.tiangolo.com/tutorial/testing/)
- [Python Testing Best Practices](https://docs.python-guide.org/writing/tests/)

## ğŸ¤ Contributing

When adding new features:

1. Write tests first (TDD approach)
2. Ensure all tests pass
3. Maintain > 80% coverage
4. Document test purpose clearly

## ğŸ“ Support

If you encounter test failures:

1. Check error messages carefully
2. Run with `-v` for verbose output
3. Use `-s` to see print statements
4. Check if you need API keys (some tests may need them)

## ğŸ“Š Test Statistics

Run this command to see test statistics:

```bash
pytest --collect-only
```

Current test count:
- **Unit tests:** 40+ tests
- **Integration tests:** 30+ tests
- **UI tests:** 30+ tests
- **Total:** 100+ tests

---

**Happy Testing! ğŸ§ª**

