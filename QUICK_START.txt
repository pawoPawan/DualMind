â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                  ğŸ§  DUALMIND AI - QUICK START                   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“ MAIN URL: http://localhost:8000

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸš€ SERVER COMMANDS

   Start:    ./dualmind.sh start
   Stop:     ./dualmind.sh stop
   Status:   ./dualmind.sh status
   Restart:  ./dualmind.sh restart
   Logs:     ./dualmind.sh logs

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

â˜ï¸  CLOUD MODE (Fast, Powerful)

   1. Go to http://localhost:8000
   2. Click "â˜ï¸ Cloud Mode"
   3. Select provider (NVIDIA recommended)
   4. Pick a model
   5. Enter API key
   6. Start chatting!

   Features:
   â€¢ 5 cloud providers
   â€¢ Dynamic model selection
   â€¢ API key validation
   â€¢ Streaming responses

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ”’ LOCAL MODE + RAG (Private, No API Key)

   1. Go to http://localhost:8000/local
   2. Select model (Phi-3-mini recommended)
   3. Click "Download & Load Model"
   4. Wait for download

   ğŸ“š UPLOAD DOCUMENTS:
   1. Click "ğŸ“š Knowledge Base"
   2. Upload TXT/MD files
   3. Wait for processing (~60ms per chunk)
   4. Close modal

   ğŸ’¬ CHAT WITH DOCUMENTS:
   â€¢ Ask questions about your content
   â€¢ Look for "ğŸ“š Answer enhanced" badge
   â€¢ RAG automatically retrieves relevant info

   ğŸ—‘ï¸ MANAGE CONTEXT:
   â€¢ Click "ğŸ—‘ï¸ Clear History" button
   â€¢ Or auto-trims after 8 messages

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“Š TOKEN BUDGET (2048 token models)

   RAG Context:     400 tokens (19.5%)
   History:         800 tokens (39.1%)
   Query:            50 tokens ( 2.4%)
   Response:        748 tokens (36.5%)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ¯ RECOMMENDED MODELS FOR RAG

   Model            Context  RAG Chunks  Best For
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   TinyLlama-1.1B    2048    1-2         Quick tests
   Phi-2             2048    2           General chat
   Phi-3-mini â­     4096    3-4         RAG (Best!)
   Llama-3.2-3B      4096    3-4         Better quality
   Llama-3.1-8B      8192    5-6         Max context

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ’¡ QUICK TIPS

   âœ… DO:
   â€¢ Use TXT or MD files for best results
   â€¢ Ask specific questions
   â€¢ Clear history every 5-10 exchanges
   â€¢ Use Phi-3-mini for RAG workloads

   âŒ DON'T:
   â€¢ Upload files > 5MB
   â€¢ Ask very long questions (>200 words)
   â€¢ Expect infinite conversation history
   â€¢ Use smallest models for heavy RAG

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ› TROUBLESHOOTING

   Problem: Context window exceeded
   Fix:     Click "ğŸ—‘ï¸ Clear History"
            Use larger model (Phi-3 or Llama-3.2-3B)

   Problem: No RAG indicator
   Fix:     Check documents uploaded
            Use keywords from documents
            Similarity must be > 0.3

   Problem: Slow performance
   Fix:     Delete unused documents
            Close other tabs
            Use smaller models

   Problem: Model won't load
   Fix:     Check internet (first time)
            Clear browser cache
            Try incognito mode

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“š DOCUMENTATION

   Main:         README.md
   RAG Guide:    RAG_GUIDE.md
   Setup:        SETUP_COMPLETE.md
   Embeddings:   TRANSFORMERS_JS_EXPLAINED.md
   Diagrams:     EMBEDDING_FLOW_DIAGRAM.md
   Fixes:        CONTEXT_WINDOW_FIX.md
   Management:   MANAGEMENT_GUIDE.md

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ” DEBUG (Open browser console F12)

   RAG Activity:
   RAG: Using context from 2 chunks
   Estimated context tokens: 350
   Similarity scores: ['0.876', '0.654']

   History Management:
   Trimmed conversation history to last 8 messages

   Errors:
   Context window exceeded. Clearing conversation history...

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âœ¨ FEATURES IMPLEMENTED

   âœ… Dual Mode (Cloud + Local)
   âœ… Multi-cloud providers (5)
   âœ… Dynamic model selection
   âœ… RAG with local embeddings
   âœ… Document upload & management
   âœ… Context window management
   âœ… Token optimization
   âœ… Streaming responses
   âœ… API key validation
   âœ… Error recovery

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ‰ STATUS: READY TO USE!

   Server:  âœ… RUNNING
   Port:    8000
   Cloud:   âœ… Available
   Local:   âœ… Available
   RAG:     âœ… Enabled

   Start: http://localhost:8000

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ§  DualMind AI - Your documents, your privacy, your AI!

